{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83e0a9f",
   "metadata": {},
   "source": [
    "\n",
    "### Collaborative Filtering Deep Dive\n",
    "\n",
    "\"\"\"\n",
    "### Collaborative Filtering: From Neighbors to Latent Factors\n",
    "==========================================================\n",
    "This notebook implements and analyzes collaborative filtering methods:\n",
    "- User-based CF with different similarity metrics\n",
    "- Item-based CF \n",
    "- Matrix Factorization (SVD)\n",
    "- Alternating Least Squares (ALS)\n",
    "- Hyperparameter tuning\n",
    "- Detailed comparison and analysis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f2dc8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 1: Imports and Setup\n",
    "# ============================================================================\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.data_loader import MovieLensLoader\n",
    "from src.preprocess import prepare_data_for_training\n",
    "from src.recommenders.collaborative import (\n",
    "    UserBasedCF,\n",
    "    ItemBasedCF,\n",
    "    MatrixFactorizationSVD,\n",
    "    AlternatingLeastSquares\n",
    ")\n",
    "from src.evaluation import RecommenderEvaluator\n",
    "from src.utils import plot_model_comparison\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88228866",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Cell 2: Load and Prepare Data\n",
    "# ============================================================================\n",
    "print(\"Loading MovieLens data...\")\n",
    "loader = MovieLensLoader()\n",
    "ratings = loader.load_ratings()\n",
    "movies = loader.load_movies()\n",
    "\n",
    "# Prepare data with user-based split (ensures all users in both sets)\n",
    "print(\"\\nPreparing train/test split...\")\n",
    "train, test, metadata = prepare_data_for_training(\n",
    "    ratings,\n",
    "    test_size=0.2,\n",
    "    split_method='user_based',\n",
    "    min_user_ratings=10,\n",
    "    min_item_ratings=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "all_items = set(ratings['item_id'].unique())\n",
    "\n",
    "print(\"\\n✓ Data loaded\")\n",
    "print(f\"  Train: {len(train):,} ratings\")\n",
    "print(f\"  Test: {len(test):,} ratings\")\n",
    "print(f\"  Users: {train['user_id'].nunique():,}\")\n",
    "print(f\"  Items: {train['item_id'].nunique():,}\")\n",
    "print(f\"  Sparsity: {metadata['sparsity']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68341572",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 3: Understanding the Data Matrix\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"UNDERSTANDING THE USER-ITEM MATRIX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create sample user-item matrix for visualization\n",
    "sample_users = train['user_id'].unique()[:20]\n",
    "sample_items = train['item_id'].unique()[:30]\n",
    "\n",
    "sample_data = train[\n",
    "    train['user_id'].isin(sample_users) & \n",
    "    train['item_id'].isin(sample_items)\n",
    "]\n",
    "\n",
    "sample_matrix = sample_data.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='item_id',\n",
    "    values='rating',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Raw ratings\n",
    "sns.heatmap(\n",
    "    sample_matrix,\n",
    "    cmap='YlOrRd',\n",
    "    cbar_kws={'label': 'Rating'},\n",
    "    ax=axes[0],\n",
    "    xticklabels=False,\n",
    "    yticklabels=True\n",
    ")\n",
    "axes[0].set_title('User-Item Rating Matrix (Sample)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Items')\n",
    "axes[0].set_ylabel('Users')\n",
    "\n",
    "# Binary (rated/not rated)\n",
    "sns.heatmap(\n",
    "    (sample_matrix > 0).astype(int),\n",
    "    cmap='RdYlGn',\n",
    "    cbar_kws={'label': 'Rated'},\n",
    "    ax=axes[1],\n",
    "    xticklabels=False,\n",
    "    yticklabels=True\n",
    ")\n",
    "axes[1].set_title('Interaction Pattern (Binary)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Items')\n",
    "axes[1].set_ylabel('Users')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSample matrix density: {(sample_matrix > 0).sum().sum() / sample_matrix.size:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed903362",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Cell 4: User-Based Collaborative Filtering\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"USER-BASED COLLABORATIVE FILTERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Training User-Based CF with Cosine Similarity...\")\n",
    "user_cf_cosine = UserBasedCF(k=50, similarity='cosine')\n",
    "start_time = time.time()\n",
    "user_cf_cosine.fit(train)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"   Training time: {train_time:.2f}s\")\n",
    "\n",
    "# Test prediction\n",
    "pred = user_cf_cosine.predict(user_id=1, item_id=100)\n",
    "print(f\"\\nSample prediction (user=1, item=100): {pred:.2f}\")\n",
    "\n",
    "# Generate recommendations\n",
    "print(\"\\nTop 10 recommendations for User 1:\")\n",
    "recs = user_cf_cosine.recommend(user_id=1, n=10, exclude_seen=True)\n",
    "for i, (item_id, score) in enumerate(recs, 1):\n",
    "    movie_title = movies[movies['item_id'] == item_id]['title'].values\n",
    "    title = movie_title[0] if len(movie_title) > 0 else \"Unknown\"\n",
    "    print(f\"  {i:2d}. {title[:50]:50s} (score: {score:.3f})\")\n",
    "\n",
    "# Compare with Pearson similarity\n",
    "print(\"\\n2. Training User-Based CF with Pearson Correlation...\")\n",
    "user_cf_pearson = UserBasedCF(k=50, similarity='pearson')\n",
    "user_cf_pearson.fit(train)\n",
    "\n",
    "# Visualize user similarity matrix (sample)\n",
    "print(\"\\n3. User Similarity Analysis\")\n",
    "sample_sim = user_cf_cosine.user_similarity[:50, :50]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    sample_sim,\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    cbar_kws={'label': 'Similarity'},\n",
    "    xticklabels=False,\n",
    "    yticklabels=False\n",
    ")\n",
    "plt.title('User Similarity Matrix (Sample - First 50 Users)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Users')\n",
    "plt.ylabel('Users')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze similarity distribution\n",
    "sim_values = user_cf_cosine.user_similarity[np.triu_indices_from(user_cf_cosine.user_similarity, k=1)]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(sim_values, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(sim_values.mean(), color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Mean: {sim_values.mean():.3f}')\n",
    "plt.title('Distribution of User Similarities', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSimilarity statistics:\")\n",
    "print(f\"  Mean: {sim_values.mean():.4f}\")\n",
    "print(f\"  Std: {sim_values.std():.4f}\")\n",
    "print(f\"  Min: {sim_values.min():.4f}\")\n",
    "print(f\"  Max: {sim_values.max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae9b66",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 5: Item-Based Collaborative Filtering\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ITEM-BASED COLLABORATIVE FILTERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Training Item-Based CF...\")\n",
    "item_cf = ItemBasedCF(k=50, similarity='cosine')\n",
    "start_time = time.time()\n",
    "item_cf.fit(train)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"   Training time: {train_time:.2f}s\")\n",
    "\n",
    "# Generate recommendations\n",
    "print(\"\\nTop 10 recommendations for User 1:\")\n",
    "recs = item_cf.recommend(user_id=1, n=10, exclude_seen=True)\n",
    "for i, (item_id, score) in enumerate(recs, 1):\n",
    "    movie_title = movies[movies['item_id'] == item_id]['title'].values\n",
    "    title = movie_title[0] if len(movie_title) > 0 else \"Unknown\"\n",
    "    print(f\"  {i:2d}. {title[:50]:50s} (score: {score:.3f})\")\n",
    "\n",
    "# Find similar items\n",
    "print(\"\\n2. Similar Items Analysis\")\n",
    "sample_item = 1  # Toy Story\n",
    "movie_title = movies[movies['item_id'] == sample_item]['title'].values[0]\n",
    "print(f\"\\nMovies similar to '{movie_title}':\")\n",
    "\n",
    "# Get item index\n",
    "item_idx = item_cf.item_id_map[sample_item]\n",
    "similarities = item_cf.item_similarity[item_idx, :]\n",
    "top_indices = np.argsort(similarities)[-11:-1][::-1]  # Top 10 (excluding itself)\n",
    "\n",
    "for rank, idx in enumerate(top_indices, 1):\n",
    "    similar_item_id = item_cf.reverse_item_map[idx]\n",
    "    sim_score = similarities[idx]\n",
    "    similar_title = movies[movies['item_id'] == similar_item_id]['title'].values\n",
    "    title = similar_title[0] if len(similar_title) > 0 else \"Unknown\"\n",
    "    print(f\"  {rank:2d}. {title[:50]:50s} (similarity: {sim_score:.3f})\")\n",
    "\n",
    "# Visualize item similarity matrix (sample)\n",
    "sample_item_sim = item_cf.item_similarity[:50, :50]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    sample_item_sim,\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    cbar_kws={'label': 'Similarity'},\n",
    "    xticklabels=False,\n",
    "    yticklabels=False\n",
    ")\n",
    "plt.title('Item Similarity Matrix (Sample - First 50 Items)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Items')\n",
    "plt.ylabel('Items')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e536a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 6: Matrix Factorization (SVD)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MATRIX FACTORIZATION (SVD)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Training SVD with 50 factors...\")\n",
    "svd_model = MatrixFactorizationSVD(n_factors=50, random_state=42)\n",
    "start_time = time.time()\n",
    "svd_model.fit(train)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"   Training time: {train_time:.2f}s\")\n",
    "\n",
    "# Analyze latent factors\n",
    "print(\"\\n2. Latent Factor Analysis\")\n",
    "print(f\"   User factors shape: {svd_model.user_factors.shape}\")\n",
    "print(f\"   Item factors shape: {svd_model.item_factors.shape}\")\n",
    "print(f\"   Singular values: {svd_model.sigma}\")\n",
    "\n",
    "# Visualize singular values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(svd_model.sigma) + 1), svd_model.sigma, \n",
    "         marker='o', linewidth=2, markersize=8)\n",
    "plt.title('Singular Values (Importance of Latent Factors)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Factor Index')\n",
    "plt.ylabel('Singular Value')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize user and item factors\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# User factors (first 2 dimensions)\n",
    "axes[0].scatter(\n",
    "    svd_model.user_factors[:, 0],\n",
    "    svd_model.user_factors[:, 1],\n",
    "    alpha=0.5,\n",
    "    s=20\n",
    ")\n",
    "axes[0].set_title('User Embeddings (First 2 Dimensions)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Factor 1')\n",
    "axes[0].set_ylabel('Factor 2')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Item factors (first 2 dimensions)\n",
    "axes[1].scatter(\n",
    "    svd_model.item_factors[:, 0],\n",
    "    svd_model.item_factors[:, 1],\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    color='coral'\n",
    ")\n",
    "axes[1].set_title('Item Embeddings (First 2 Dimensions)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Factor 1')\n",
    "axes[1].set_ylabel('Factor 2')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate recommendations\n",
    "print(\"\\nTop 10 recommendations for User 1:\")\n",
    "recs = svd_model.recommend(user_id=1, n=10, exclude_seen=True)\n",
    "for i, (item_id, score) in enumerate(recs, 1):\n",
    "    movie_title = movies[movies['item_id'] == item_id]['title'].values\n",
    "    title = movie_title[0] if len(movie_title) > 0 else \"Unknown\"\n",
    "    print(f\"  {i:2d}. {title[:50]:50s} (score: {score:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2179f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 7: Alternating Least Squares (ALS)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALTERNATING LEAST SQUARES (ALS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Training ALS...\")\n",
    "als_model = AlternatingLeastSquares(\n",
    "    n_factors=20,\n",
    "    regularization=0.01,\n",
    "    iterations=15,\n",
    "    random_state=42\n",
    ")\n",
    "start_time = time.time()\n",
    "als_model.fit(train)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"   Total training time: {train_time:.2f}s\")\n",
    "\n",
    "# Generate recommendations\n",
    "print(\"\\nTop 10 recommendations for User 1:\")\n",
    "recs = als_model.recommend(user_id=1, n=10, exclude_seen=True)\n",
    "for i, (item_id, score) in enumerate(recs, 1):\n",
    "    movie_title = movies[movies['item_id'] == item_id]['title'].values\n",
    "    title = movie_title[0] if len(movie_title) > 0 else \"Unknown\"\n",
    "    print(f\"  {i:2d}. {title[:50]:50s} (score: {score:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69763b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Cell 8: Hyperparameter Tuning - K Neighbors\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING: K NEIGHBORS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "k_values = [10, 20, 30, 50, 75, 100]\n",
    "results_by_k = []\n",
    "\n",
    "evaluator = RecommenderEvaluator(k_values=[10])\n",
    "\n",
    "print(\"\\nTesting different K values for Item-Based CF...\")\n",
    "for k in k_values:\n",
    "    print(f\"\\n  Testing k={k}...\")\n",
    "    model = ItemBasedCF(k=k, similarity='cosine')\n",
    "    model.fit(train)\n",
    "    \n",
    "    results = evaluator.evaluate_model(\n",
    "        model, test, train, all_items,\n",
    "        n_recommendations=10,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    results_by_k.append({\n",
    "        'k': k,\n",
    "        'NDCG@10': results['NDCG@10'],\n",
    "        'Precision@10': results['Precision@10'],\n",
    "        'Recall@10': results['Recall@10'],\n",
    "        'Coverage': results['Coverage']\n",
    "    })\n",
    "\n",
    "k_results_df = pd.DataFrame(results_by_k)\n",
    "print(\"\\nResults by K:\")\n",
    "print(k_results_df)\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['NDCG@10', 'Precision@10', 'Recall@10', 'Coverage']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    ax.plot(k_results_df['k'], k_results_df[metric], \n",
    "            marker='o', linewidth=2, markersize=8)\n",
    "    ax.set_title(f'{metric} vs K', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('K (Number of Neighbors)')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Mark best value\n",
    "    best_idx = k_results_df[metric].idxmax() if metric != 'Coverage' else k_results_df[metric].idxmax()\n",
    "    best_k = k_results_df.loc[best_idx, 'k']\n",
    "    best_val = k_results_df.loc[best_idx, metric]\n",
    "    ax.axvline(best_k, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.annotate(f'Best: k={int(best_k)}', \n",
    "                xy=(best_k, best_val),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ca909",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 9: Hyperparameter Tuning - Latent Factors\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING: LATENT FACTORS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "factor_values = [10, 20, 30, 50, 75, 100]\n",
    "results_by_factors = []\n",
    "\n",
    "print(\"\\nTesting different number of latent factors for SVD...\")\n",
    "for n_factors in factor_values:\n",
    "    if n_factors > min(train['user_id'].nunique(), train['item_id'].nunique()) - 1:\n",
    "        print(f\"  Skipping n_factors={n_factors} (too large)\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n  Testing n_factors={n_factors}...\")\n",
    "    model = MatrixFactorizationSVD(n_factors=n_factors, random_state=42)\n",
    "    model.fit(train)\n",
    "    \n",
    "    results = evaluator.evaluate_model(\n",
    "        model, test, train, all_items,\n",
    "        n_recommendations=10,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    results_by_factors.append({\n",
    "        'n_factors': n_factors,\n",
    "        'NDCG@10': results['NDCG@10'],\n",
    "        'Precision@10': results['Precision@10'],\n",
    "        'Recall@10': results['Recall@10'],\n",
    "        'RMSE': results['RMSE']\n",
    "    })\n",
    "\n",
    "factors_results_df = pd.DataFrame(results_by_factors)\n",
    "print(\"\\nResults by Number of Factors:\")\n",
    "print(factors_results_df)\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['NDCG@10', 'Precision@10', 'Recall@10', 'RMSE']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    ax.plot(factors_results_df['n_factors'], factors_results_df[metric], \n",
    "            marker='o', linewidth=2, markersize=8, color='coral')\n",
    "    ax.set_title(f'{metric} vs Number of Factors', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Number of Latent Factors')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Mark best value\n",
    "    if metric == 'RMSE':\n",
    "        best_idx = factors_results_df[metric].idxmin()\n",
    "    else:\n",
    "        best_idx = factors_results_df[metric].idxmax()\n",
    "    best_factors = factors_results_df.loc[best_idx, 'n_factors']\n",
    "    best_val = factors_results_df.loc[best_idx, metric]\n",
    "    ax.axvline(best_factors, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.annotate(f'Best: {int(best_factors)}', \n",
    "                xy=(best_factors, best_val),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3a014",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 10: Comprehensive Model Comparison\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use best hyperparameters from tuning\n",
    "best_k = k_results_df.loc[k_results_df['NDCG@10'].idxmax(), 'k']\n",
    "best_factors = factors_results_df.loc[factors_results_df['NDCG@10'].idxmax(), 'n_factors']\n",
    "\n",
    "print(f\"\\nUsing optimized hyperparameters:\")\n",
    "print(f\"  Best K for neighborhood methods: {int(best_k)}\")\n",
    "print(f\"  Best latent factors for MF: {int(best_factors)}\")\n",
    "\n",
    "# Train all models with best params\n",
    "models = {}\n",
    "\n",
    "print(\"\\nTraining models...\")\n",
    "models['User-CF'] = UserBasedCF(k=int(best_k), similarity='cosine')\n",
    "models['User-CF'].fit(train)\n",
    "\n",
    "models['Item-CF'] = ItemBasedCF(k=int(best_k), similarity='cosine')\n",
    "models['Item-CF'].fit(train)\n",
    "\n",
    "models['SVD'] = MatrixFactorizationSVD(n_factors=int(best_factors), random_state=42)\n",
    "models['SVD'].fit(train)\n",
    "\n",
    "models['ALS'] = AlternatingLeastSquares(n_factors=20, regularization=0.01, iterations=10)\n",
    "models['ALS'].fit(train)\n",
    "\n",
    "# Evaluate all models\n",
    "evaluator_full = RecommenderEvaluator(k_values=[5, 10, 20])\n",
    "results_df = evaluator_full.compare_models(\n",
    "    models=models,\n",
    "    test_data=test,\n",
    "    train_data=train,\n",
    "    all_items=all_items,\n",
    "    n_recommendations=10\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(results_df)\n",
    "\n",
    "# Visualize comparison\n",
    "key_metrics = ['Precision@10', 'Recall@10', 'NDCG@10', 'Coverage', 'RMSE']\n",
    "plot_model_comparison(results_df, metrics=key_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe5617",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Cell 11: Recommendation Quality Analysis\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATION QUALITY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Analyze recommendations for a sample user\n",
    "sample_user = 10\n",
    "user_train_items = set(train[train['user_id'] == sample_user]['item_id'])\n",
    "\n",
    "print(f\"\\nUser {sample_user} has rated {len(user_train_items)} items in training set\")\n",
    "print(\"\\nMovies rated by user:\")\n",
    "for item_id in list(user_train_items)[:5]:\n",
    "    movie_title = movies[movies['item_id'] == item_id]['title'].values\n",
    "    title = movie_title[0] if len(movie_title) > 0 else \"Unknown\"\n",
    "    rating = train[(train['user_id'] == sample_user) & (train['item_id'] == item_id)]['rating'].values[0]\n",
    "    print(f\"  • {title[:50]:50s} (rating: {rating})\")\n",
    "\n",
    "print(\"\\nRecommendations from different models:\")\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    recs = model.recommend(user_id=sample_user, n=5, exclude_seen=True, seen_items=user_train_items)\n",
    "    for i, (item_id, score) in enumerate(recs, 1):\n",
    "        movie_title = movies[movies['item_id'] == item_id]['title'].values\n",
    "        title = movie_title[0] if len(movie_title) > 0 else \"Unknown\"\n",
    "        print(f\"  {i}. {title[:45]:45s} (score: {score:.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc135a60",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 12: Key Insights and Learnings\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHTS FROM COLLABORATIVE FILTERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_model = results_df['NDCG@10'].idxmax()\n",
    "best_ndcg = results_df.loc[best_model, 'NDCG@10']\n",
    "\n",
    "insights = f\"\"\"\n",
    "🎯 PERFORMANCE SUMMARY:\n",
    "   • Best model: {best_model} (NDCG@10: {best_ndcg:.4f})\n",
    "   • Item-CF typically outperforms User-CF for sparse data\n",
    "   • Matrix factorization provides good balance of accuracy and efficiency\n",
    "   • Optimal K for neighborhoods: {int(best_k)}\n",
    "   • Optimal latent factors: {int(best_factors)}\n",
    "\n",
    "📊 USER-BASED vs ITEM-BASED CF:\n",
    "   • Item-based is more stable (item similarities change less over time)\n",
    "   • User-based can capture more diverse preferences\n",
    "   • Item-based scales better with more users\n",
    "   • User-based may perform better with dense data\n",
    "\n",
    "🔬 MATRIX FACTORIZATION INSIGHTS:\n",
    "   • SVD captures latent factors efficiently\n",
    "   • More factors = more expressiveness but risk of overfitting\n",
    "   • ALS handles implicit feedback well\n",
    "   • Regularization is crucial for generalization\n",
    "\n",
    "⚡ COMPUTATIONAL CONSIDERATIONS:\n",
    "   • Neighborhood methods: O(n²) similarity computation\n",
    "   • Matrix factorization: O(k·n·m) where k is iterations\n",
    "   • Item-CF can precompute similarities (better for real-time)\n",
    "   • SVD one-time computation, fast inference\n",
    "\n",
    "🎭 COLD START HANDLING:\n",
    "   • User-CF struggles with new users (no ratings history)\n",
    "   • Item-CF struggles with new items (no rating history)\n",
    "   • Matrix factorization cannot handle completely new users/items\n",
    "   • Need content-based or hybrid approaches for cold start\n",
    "\n",
    "🚀 PRODUCTION RECOMMENDATIONS:\n",
    "   • Use Item-CF for interpretability and real-time updates\n",
    "   • Use matrix factorization for batch recommendations\n",
    "   • Consider hybrid approach for best of both worlds\n",
    "   • Implement incremental updates for efficiency\n",
    "\"\"\"\n",
    "\n",
    "print(insights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25731a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 13: Save Results and Models\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING RESULTS AND MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save evaluation results\n",
    "results_df.to_csv('../data/processed/collaborative_filtering_results.csv')\n",
    "k_results_df.to_csv('../data/processed/k_tuning_results.csv')\n",
    "factors_results_df.to_csv('../data/processed/factors_tuning_results.csv')\n",
    "\n",
    "print(\"✓ Results saved to data/processed/\")\n",
    "\n",
    "# Save best models\n",
    "best_item_cf = models['Item-CF']\n",
    "best_svd = models['SVD']\n",
    "\n",
    "best_item_cf.save('../models/item_cf_best.pkl')\n",
    "best_svd.save('../models/svd_best.pkl')\n",
    "\n",
    "print(\"✓ Best models saved to models/\")\n",
    "print(\"\\n✅ Collaborative filtering analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
