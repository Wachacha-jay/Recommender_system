{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b984d1d",
   "metadata": {},
   "source": [
    "\n",
    "### Baseline Recommendation Models\n",
    "===============================\n",
    "\n",
    "This notebook implements and evaluates baseline recommenders:\n",
    "- Random recommender\n",
    "- Popularity-based recommenders\n",
    "- Time-decay popularity\n",
    "- Trending items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda0e7e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 1: Imports and Setup\n",
    "# ============================================================================\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data_loader import MovieLensLoader\n",
    "from src.preprocess import prepare_data_for_training\n",
    "from src.recommenders.popularity import (\n",
    "    RandomRecommender,\n",
    "    PopularityRecommender,\n",
    "    TimeDecayPopularityRecommender,\n",
    "    TrendingRecommender\n",
    ")\n",
    "from src.evaluation import RecommenderEvaluator\n",
    "from src.utils import plot_model_comparison\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Imports successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55565a37",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 2: Load and Prepare Data\n",
    "# ============================================================================\n",
    "print(\"Loading data...\")\n",
    "loader = MovieLensLoader()\n",
    "ratings = loader.load_ratings()\n",
    "movies = loader.load_movies()\n",
    "\n",
    "# Prepare train/test split\n",
    "print(\"\\nPreparing train/test split...\")\n",
    "train, test, metadata = prepare_data_for_training(\n",
    "    ratings,\n",
    "    test_size=0.2,\n",
    "    split_method='user_based',\n",
    "    min_user_ratings=5,\n",
    "    min_item_ratings=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "all_items = set(ratings['item_id'].unique())\n",
    "\n",
    "print(\"\\n‚úì Data preparation complete\")\n",
    "print(f\"  Train: {len(train):,} ratings\")\n",
    "print(f\"  Test: {len(test):,} ratings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a022fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 3: Train Random Baseline\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. RANDOM RECOMMENDER (Baseline)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "random_rec = RandomRecommender(random_state=42)\n",
    "random_rec.fit(train)\n",
    "\n",
    "# Test predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "for user_id in [1, 10, 50]:\n",
    "    for item_id in [1, 100, 500]:\n",
    "        pred = random_rec.predict(user_id, item_id)\n",
    "        print(f\"  User {user_id}, Item {item_id}: {pred:.2f}\")\n",
    "\n",
    "# Generate recommendations\n",
    "print(\"\\nSample recommendations for user 1:\")\n",
    "recs = random_rec.recommend(user_id=1, n=10)\n",
    "for i, (item_id, score) in enumerate(recs, 1):\n",
    "    movie_title = movies[movies['item_id'] == item_id]['title'].values\n",
    "    title = movie_title[0] if len(movie_title) > 0 else \"Unknown\"\n",
    "    print(f\"  {i}. {title} (score: {score:.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936e90e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 4: Train Popularity Recommenders\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. POPULARITY-BASED RECOMMENDERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Count-based popularity\n",
    "print(\"\\n2a. Popularity (Count-based)\")\n",
    "pop_count = PopularityRecommender(method='count')\n",
    "pop_count.fit(train)\n",
    "\n",
    "print(\"\\nTop 10 most popular items:\")\n",
    "recs = pop_count.recommend(user_id=1, n=10, exclude_seen=False)\n",
    "for i, (item_id, score) in enumerate(recs, 1):\n",
    "    movie_title = movies[movies['item_id'] == item_id]['title'].values\n",
    "    title = movie_title[0] if len(movie_title) > 0 else \"Unknown\"\n",
    "    print(f\"  {i}. {title} (score: {score:.3f})\")\n",
    "\n",
    "# Average rating popularity\n",
    "print(\"\\n2b. Popularity (Average Rating)\")\n",
    "pop_avg = PopularityRecommender(method='average')\n",
    "pop_avg.fit(train)\n",
    "\n",
    "# Weighted popularity\n",
    "print(\"\\n2c. Popularity (Weighted)\")\n",
    "pop_weighted = PopularityRecommender(method='weighted')\n",
    "pop_weighted.fit(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb066d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 5: Train Time-Decay Popularity\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. TIME-DECAY POPULARITY RECOMMENDER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "time_decay_rec = TimeDecayPopularityRecommender(decay_rate=0.95, time_unit='days')\n",
    "time_decay_rec.fit(train)\n",
    "\n",
    "print(\"\\nTop 10 recommendations (with time decay):\")\n",
    "recs = time_decay_rec.recommend(user_id=1, n=10, exclude_seen=False)\n",
    "for i, (item_id, score) in enumerate(recs, 1):\n",
    "    movie_title = movies[movies['item_id'] == item_id]['title'].values\n",
    "    title = movie_title[0] if len(movie_title) > 0 else \"Unknown\"\n",
    "    print(f\"  {i}. {title} (score: {score:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b5664",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 6: Train Trending Recommender\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. TRENDING RECOMMENDER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "trending_rec = TrendingRecommender(window_days=30)\n",
    "trending_rec.fit(train)\n",
    "\n",
    "print(\"\\nTop 10 trending items:\")\n",
    "recs = trending_rec.recommend(user_id=1, n=10, exclude_seen=False)\n",
    "for i, (item_id, score) in enumerate(recs, 1):\n",
    "    movie_title = movies[movies['item_id'] == item_id]['title'].values\n",
    "    title = movie_title[0] if len(movie_title) > 0 else \"Unknown\"\n",
    "    print(f\"  {i}. {title} (score: {score:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36766e22",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 7: Evaluate All Baselines\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "evaluator = RecommenderEvaluator(k_values=[5, 10, 20])\n",
    "\n",
    "models = {\n",
    "    'Random': random_rec,\n",
    "    'Pop-Count': pop_count,\n",
    "    'Pop-Average': pop_avg,\n",
    "    'Pop-Weighted': pop_weighted,\n",
    "    'Time-Decay': time_decay_rec,\n",
    "    'Trending': trending_rec\n",
    "}\n",
    "\n",
    "results_df = evaluator.compare_models(\n",
    "    models=models,\n",
    "    test_data=test,\n",
    "    train_data=train,\n",
    "    all_items=all_items,\n",
    "    n_recommendations=10\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e72bad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 8: Visualize Results\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select key metrics to plot\n",
    "key_metrics = ['Precision@10', 'Recall@10', 'NDCG@10', 'Coverage', 'RMSE']\n",
    "plot_model_comparison(results_df, metrics=key_metrics)\n",
    "\n",
    "# Plot all metrics at different K values\n",
    "precision_metrics = [col for col in results_df.columns if 'Precision@' in col]\n",
    "recall_metrics = [col for col in results_df.columns if 'Recall@' in col]\n",
    "ndcg_metrics = [col for col in results_df.columns if 'NDCG@' in col]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Precision@K\n",
    "results_df[precision_metrics].T.plot(kind='line', ax=axes[0], marker='o', linewidth=2)\n",
    "axes[0].set_title('Precision@K', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('K')\n",
    "axes[0].set_ylabel('Precision')\n",
    "axes[0].set_xticklabels([col.split('@')[1] for col in precision_metrics])\n",
    "axes[0].legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Recall@K\n",
    "results_df[recall_metrics].T.plot(kind='line', ax=axes[1], marker='o', linewidth=2)\n",
    "axes[1].set_title('Recall@K', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('K')\n",
    "axes[1].set_ylabel('Recall')\n",
    "axes[1].set_xticklabels([col.split('@')[1] for col in recall_metrics])\n",
    "axes[1].legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# NDCG@K\n",
    "results_df[ndcg_metrics].T.plot(kind='line', ax=axes[2], marker='o', linewidth=2)\n",
    "axes[2].set_title('NDCG@K', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('K')\n",
    "axes[2].set_ylabel('NDCG')\n",
    "axes[2].set_xticklabels([col.split('@')[1] for col in ndcg_metrics])\n",
    "axes[2].legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e7104",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 9: Analyze Coverage and Diversity\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COVERAGE AND DIVERSITY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Coverage comparison\n",
    "print(\"\\nCatalog Coverage:\")\n",
    "for model_name, model in models.items():\n",
    "    coverage = results_df.loc[model_name, 'Coverage']\n",
    "    print(f\"  {model_name:15s}: {coverage:.4f} ({coverage*len(all_items):.0f}/{len(all_items)} items)\")\n",
    "\n",
    "# Visualize coverage\n",
    "plt.figure(figsize=(10, 6))\n",
    "coverage_data = results_df['Coverage'].sort_values(ascending=False)\n",
    "coverage_data.plot(kind='barh', color='teal', edgecolor='black')\n",
    "plt.title('Catalog Coverage by Model', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Coverage')\n",
    "plt.xlim(0, 1)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d92d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 10: Recommendation Overlap Analysis\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATION OVERLAP ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get recommendations from all models for a sample user\n",
    "sample_user = 1\n",
    "all_recs = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    recs = model.recommend(user_id=sample_user, n=20, exclude_seen=True)\n",
    "    all_recs[model_name] = set([item_id for item_id, _ in recs])\n",
    "\n",
    "# Calculate overlap matrix\n",
    "overlap_matrix = pd.DataFrame(\n",
    "    index=models.keys(),\n",
    "    columns=models.keys(),\n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "for model1 in models.keys():\n",
    "    for model2 in models.keys():\n",
    "        if model1 in all_recs and model2 in all_recs:\n",
    "            overlap = len(all_recs[model1] & all_recs[model2])\n",
    "            overlap_matrix.loc[model1, model2] = overlap / 20.0\n",
    "\n",
    "print(f\"\\nRecommendation Overlap for User {sample_user} (Top-20):\")\n",
    "print(overlap_matrix)\n",
    "\n",
    "# Visualize overlap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    overlap_matrix.astype(float),\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='YlOrRd',\n",
    "    cbar_kws={'label': 'Overlap Ratio'},\n",
    "    square=True\n",
    ")\n",
    "plt.title('Recommendation Overlap Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b1a44",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 11: Key Insights\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHTS FROM BASELINE MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_precision = results_df['Precision@10'].idxmax()\n",
    "best_recall = results_df['Recall@10'].idxmax()\n",
    "best_ndcg = results_df['NDCG@10'].idxmax()\n",
    "best_coverage = results_df['Coverage'].idxmax()\n",
    "best_rmse = results_df['RMSE'].idxmin()\n",
    "\n",
    "insights = f\"\"\"\n",
    "üéØ PERFORMANCE SUMMARY:\n",
    "   ‚Ä¢ Best Precision@10: {best_precision} ({results_df.loc[best_precision, 'Precision@10']:.4f})\n",
    "   ‚Ä¢ Best Recall@10: {best_recall} ({results_df.loc[best_recall, 'Recall@10']:.4f})\n",
    "   ‚Ä¢ Best NDCG@10: {best_ndcg} ({results_df.loc[best_ndcg, 'NDCG@10']:.4f})\n",
    "   ‚Ä¢ Best Coverage: {best_coverage} ({results_df.loc[best_coverage, 'Coverage']:.4f})\n",
    "   ‚Ä¢ Best RMSE: {best_rmse} ({results_df.loc[best_rmse, 'RMSE']:.4f})\n",
    "\n",
    "üí° OBSERVATIONS:\n",
    "   ‚Ä¢ Random baseline performs poorly (as expected)\n",
    "   ‚Ä¢ Popularity-based methods show reasonable performance\n",
    "   ‚Ä¢ Weighted popularity balances count and quality\n",
    "   ‚Ä¢ Time-decay and trending capture temporal dynamics\n",
    "   ‚Ä¢ All baselines have similar RMSE (predicting average)\n",
    "\n",
    "‚ö†Ô∏è LIMITATIONS:\n",
    "   ‚Ä¢ All baselines recommend same items to all users (no personalization)\n",
    "   ‚Ä¢ High coverage but low precision/recall\n",
    "   ‚Ä¢ Cannot capture user-specific preferences\n",
    "   ‚Ä¢ Suffer from popularity bias\n",
    "\n",
    "üöÄ NEXT STEPS:\n",
    "   ‚Ä¢ Implement collaborative filtering for personalization\n",
    "   ‚Ä¢ Try content-based methods for cold-start items\n",
    "   ‚Ä¢ Combine approaches in hybrid models\n",
    "\"\"\"\n",
    "\n",
    "print(insights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de447be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 12: Save Results\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save evaluation results\n",
    "results_df.to_csv('../data/processed/baseline_results.csv')\n",
    "print(\"‚úì Results saved to data/processed/baseline_results.csv\")\n",
    "\n",
    "# Save best models\n",
    "import pickle\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "pop_weighted.save('../models/popularity_weighted.pkl')\n",
    "time_decay_rec.save('../models/time_decay.pkl')\n",
    "\n",
    "print(\"‚úì Best models saved to models/\")\n",
    "print(\"\\n‚úÖ Baseline evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
